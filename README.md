Code directory

The below is the same content as "code_directory.docx"

Run on longleaf:
od_coordinate_prep.R -  generates NConly_2018_unique_od_filtered_coordinates.csv
 for use in routing – csv of all unique block group centroid – placekey location pairs in 2018 data.

Run on personal computer:
OSM.Rmd – helper script to semi-manually identify the OSM ids corresponding to locations of each expansion
osrm_run_large.jl – generates many .gpkgs (NC_2018_unique_od_filtered_paths_xxx.gpkg ) of routes for all OD pairs in NConly_2018_unique_od_filtered_coordinates.csv


Run on processing computer:
ncdot_data.Rmd – reading and processing NC DOT provided expansion data to spatial data, using OSM shapefiles
poi_filtering.R – copied from longleaf but this version is now the master version. This filters the destinations in poi_info to just the NAICS categories I’m interested in, and creates the poi_subset_placekeys_naics_borderlabel.csv 
combine_months.R – takes all of the od_home monthly safegraph files (eg NC_monthlypatterns_od_home_2018-01.csv) and combines them into one file. Only includes placekeys in poi_subset_placekeys.csv (generated by poi_filtering.R) and only includes origins from within NC. Combined file is od_home_combined_filtered.csv
add_distances_odhomedata.R – adds distances between origins and destinations to od_home_combined_filtered.csv and generates od_home_combined_filtered_dists.csv
label_od_habitual.R and label_od.R (deprecated) – takes all_expansions_ncdot_data.shp and joins with each of the many route files (NC_2018_unique_od_filtered_paths_xxx.gpkg) to label, at the destination level, whether a poi is “served” by a road by checking for overlap and then doing a nearest-neighbor relabel of the unlabeled or FALSE points. Habitual version uses only od pairs that appear in 6/12 months. Produces dest_level_labeling/placekey_habitual_labels_nn.gpkg
alldata_expansion.R – takes od_home_combined_filtered_dists.csv and removes near-border destinations (using poi_subset_placekeys_naics_borderlabel.csv), then combines with placekey_habitual_labels_nn.gpkg to get segment presence labels. Then adds expanded_ columns based on presence columns and expansion dates from all_expansions_ncdot_data.shp. Saves result to alldata_nozeros.csv
refined_control.R – takes alldata_nozeros.csv and restricts to only those destinations within the “influence area” of the segments – that is, restricts which points can be used as ‘controls’. For each road segment, finds buffer distance at which 95% of the “trues” are within the buffer area. Then restricts all data to just placekeys within that distance. This restricted dataset is called alldata_nozeros_refinedcontrol.csv and has 27,822,484 rows, from 6,331,118 distinct placekey-cbg pairs. Groups to destination level and finds avg dist, total count, and quantiles – this is written to alldata_nozeros_refinedcontrol_destgrouped.csv.
aadt.R – find Annual Average Daily Traffic from AADT stations near each expanded roadway.
Synth.Rmd – the synthetic control analysis! Reads alldata_nozeros_refinedcontrol_destgrouped.csv and adds contract info. Selects destinations present in different # of months of data. Runs microsynth on 12 treatments (segments) for two different sets of destinations (60-month and 57-month). Makes figures from all synthetic control runs.
figures.Rmd – additional figures not generated in other scripts.


Partial list of deprecated code, not included:
reshape_labeled_data.R and reshape_labeled_data_func.R (deprecated) – FLAG: poorly named. Takes all non-border destinations from od_home_combined_filtered.csv and tests filling in 0s in a sample of 1000, then adding expanded T/F columns based on placekey_habitual_labels_nn.gpkg and dates from all_expansions_ncdot_data.shp. Needs to be rewritten/scrapped because I have a more memory-efficient solution for the expansion-date labeling in agg_model.R now
agg_model.R – uses alldata_nozeros.csv to fit a model where data are aggregated to destination level. Deprecated, used fixed effects model
disagg_model.R – uses alldata_wzeros_refinedcontrol.sqlite3 and samples 10,000 destinations to fit a model where data are kept at the origin-destination pair level. Deprecated, used fixed effects model
model_run_test.R – holder for testing out model runs, will be split into scripts	
figures.R – generally makes figures, in progress
expansion_data_prep.R – adds information about expansions (e.g. roadway class, construction time?, distance to border) for use in model
fill_zeros.R – wacky order, but takes alldata_nozeros_refinedcontrol.csv, keeps just placekey, visitor_home_cbgs, date_range_start, and count columns, and fills in 0 counts for placekey-visitor_home_cbgs pairs that exist in the data but are missing for a particular date – one half of the data at a time. Then recreates the work in alldata_expansion.R – adds presence labels and expansion labels – to each half, and writes to disk: halfdata _wzeros.csv  and otherhalfdata_wzeros.csv. Then recreates work from add_distances_odhomedata.R  by adding previously-calculated OD distances to each half-data set, and saves to disk again (overwriting halfdata _wzeros.csv  and otherhalfdata_wzeros.csv). 
Between fill_zeros and future steps I used cat on the command line to combine the two halves (halfdata _wzeros.csv  and otherhalfdata_wzeros.csv ) into one giant file - alldata_wzeros_refinedcontrol.csv
Fill_zeros_sample.R – turns out the massive dataset produced by fill_zeros is way too big to analyze, so this does all the same steps as fill_zeros but just to a sample of 9000 destinations (about a third of the refined-control set). Produces for_analysis/sample9000_wzeros_refinedcontrol.csv
import.sql -  turns giant giant csv (alldata_wzeros_refinedcontrol.csv) into sqlite reference to be able to load/query parts of the data in other scripts. Run from commandline:
	sqlite3 alldata_wzeros_refinedcontrol.sqlite3 < ../code/import.sql
	generates alldata_wzeros_refinedcontrol.sqlite3
synth_bg.Rmd -  abandoned attempt to do block-group level matching rather than destination-level
